{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data to hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preproccess_one(filename, size):\n",
    "    img = Image.open(filename)\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize(size=size, resample=Image.LANCZOS)\n",
    "    img = np.asarray(img) / 255.0\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "def _preprocess(path, size, label):\n",
    "    files = list(path.glob('*'))\n",
    "    nfiles = len(files)\n",
    "    x = np.zeros((nfiles, *size, 3), dtype=np.float32)\n",
    "    print(f\"0 / {nfiles}\", end='\\r')\n",
    "    for j, f in enumerate(files):\n",
    "        x[j] = _preproccess_one(f, size=size)\n",
    "        print(f\"{j + 1} / {nfiles}\", end='\\r')\n",
    "    print()\n",
    "    return x, np.zeros(nfiles, dtype=np.uint8) + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_one_to_hdf5(fp, size):\n",
    "    print(f\"++ Saving size {size}\")\n",
    "    s = \"_\".join(map(str, size))\n",
    "    x0, y0 = _preprocess(Path('data/gbm/'), size=size, label=0)\n",
    "    x1, y1 = _preprocess(Path('data/pcnsl/'), size=size, label=1)\n",
    "    with h5py.File(fp, mode='a') as f:\n",
    "        f.create_dataset(f'/gbm/{s}/features', data=x0, compression='lzf')\n",
    "        f.create_dataset(f'/gbm/{s}/labels', data=y0, compression='lzf')\n",
    "        f.create_dataset(f'/pcnsl/{s}/features', data=x1, compression='lzf')\n",
    "        f.create_dataset(f'/pcnsl/{s}/labels', data=y1, compression='lzf')\n",
    "\n",
    "sizes = [(224, 224), (300, 300), (380, 380), (600, 600)]\n",
    "\n",
    "for size in sizes:\n",
    "    save_one_to_hdf5('data.h5', size=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tfk.layers\n",
    "\n",
    "def load_data(filename, size=\"224_224\"):\n",
    "    s = size\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        x_gbm = f[f'/gbm/{s}/features'][:]\n",
    "        y_gbm = f[f'/gbm/{s}/labels'][:]\n",
    "        x_pcnsl = f[f'/pcnsl/{s}/features'][:]\n",
    "        y_pcnsl = f[f'/pcnsl/{s}/labels'][:]\n",
    "\n",
    "    # Transform from range [0, 1] to range [-1, 1].\n",
    "    x_pcnsl *= 2.0\n",
    "    x_pcnsl -= 1.0\n",
    "    x_gbm *= 2.0\n",
    "    x_gbm -= 1.0\n",
    "\n",
    "    print(\"gbm features shape\", x_gbm.shape)\n",
    "    print(\"gbm labels shape\", y_gbm.shape)\n",
    "    print(\"pcnsl features shape\", x_pcnsl.shape)\n",
    "    print(\"pcnsl labels shape\", y_pcnsl.shape)\n",
    "    \n",
    "    x = np.concatenate((x_gbm, x_pcnsl))\n",
    "    y = np.concatenate((y_gbm, y_pcnsl))\n",
    "    y = y.astype(np.float32)\n",
    "    \n",
    "    # Shuffling turns out to be very important...\n",
    "    shuffle_inds = np.arange(y.shape[0])\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(shuffle_inds)\n",
    "    x = x[shuffle_inds]\n",
    "    y = y[shuffle_inds]\n",
    "    \n",
    "    inds = np.random.choice([0, 1, 2], size=y.size, p=[0.7, 0.2, 0.1])\n",
    "    x_train, y_train = x[inds==0], y[inds==0]\n",
    "    x_val, y_val = x[inds==1], y[inds==1]\n",
    "    x_test, y_test = x[inds==2], y[inds==2]\n",
    "    \n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
    "\n",
    "def get_datasets(filename, size=\"224_224\", batch_size=32):\n",
    "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = load_data(filename, size=size)\n",
    "    \n",
    "    n_train = y_train.shape[0] // batch_size\n",
    "    n_val = y_val.shape[0] // batch_size\n",
    "    n_test = y_test.shape[0] // batch_size\n",
    "\n",
    "    def augment(x, y):\n",
    "        x = tf.image.random_brightness(x, max_delta=2)\n",
    "        x = tf.image.random_flip_left_right(x)\n",
    "        x = tf.image.random_flip_up_down(x)\n",
    "        x = tf.image.random_hue(x, max_delta=0.25)\n",
    "        return x, y\n",
    "\n",
    "    d_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    d_train = d_train.map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    d_train = d_train.shuffle(1000, reshuffle_each_iteration=True)\n",
    "    d_train = d_train.batch(batch_size, drop_remainder=True)\n",
    "    d_train = d_train.repeat()\n",
    "    \n",
    "    d_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "    d_val = d_val.batch(batch_size, drop_remainder=True)\n",
    "    d_val = d_val.repeat()\n",
    "    \n",
    "    d_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    d_test = d_test.batch(batch_size, drop_remainder=True)\n",
    "    d_test = d_test.repeat()\n",
    "    \n",
    "    return (d_train, n_train), (d_val, n_val), (d_test, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:paola]",
   "language": "python",
   "name": "conda-env-paola-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
